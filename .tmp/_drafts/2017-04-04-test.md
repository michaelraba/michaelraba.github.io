---
title: Test
permalink: /blog/test2
date: 2017-04-04T06:41:34+00:00
author: stuart
---


# Using python to explore Wikipedia pageview data for all current members of the U.S. Congress

By Stuart Geiger (@staeiou, User:Staeiou), licensed under the MIT license

Did you know that Wikipedia has been tracking aggregate, anonymized, hourly data about the number of times each page is viewed? There are [data dumps](http://stats.grok.se/), an [API](https://wikitech.wikimedia.org/wiki/Analytics/PageviewAPI), and a [web tool](https://tools.wmflabs.org/pageviews/?project=en.wikipedia.org&platform=all-access&agent=user&range=latest-20&pages=Cat|Dog) for exploring small sets of pages (see [this blog post](https://blog.wikimedia.org/2015/12/14/pageview-data-easily-accessible/) for more on those three). In this notebook, I show how to use python to get data on hundreds of pages at once -- every current member of the U.S. Senate and House of Representatives.

## Libraries

We're using mwviews for getting the pageview data, pandas for the dataframe, and seaborn/matplotlib for plotting. pywikibot is in here because I tried to use it to get titles programmatically, but gave up.



```python
!pip install mwviews pywikibot seaborn pandas
```

    Requirement already satisfied: mwviews in /home/staeiou/anaconda3/lib/python3.6/site-packages
    Requirement already satisfied: pywikibot in /home/staeiou/anaconda3/lib/python3.6/site-packages
    Requirement already satisfied: seaborn in /home/staeiou/anaconda3/lib/python3.6/site-packages
    Requirement already satisfied: pandas in /home/staeiou/anaconda3/lib/python3.6/site-packages
    Requirement already satisfied: futures in /home/staeiou/anaconda3/lib/python3.6/site-packages (from mwviews)
    Requirement already satisfied: requests in /home/staeiou/anaconda3/lib/python3.6/site-packages (from mwviews)
    Requirement already satisfied: httplib2>=0.9 in /home/staeiou/anaconda3/lib/python3.6/site-packages (from pywikibot)
    Requirement already satisfied: python-dateutil>=2 in /home/staeiou/anaconda3/lib/python3.6/site-packages (from pandas)
    Requirement already satisfied: pytz>=2011k in /home/staeiou/anaconda3/lib/python3.6/site-packages (from pandas)
    Requirement already satisfied: numpy>=1.7.0 in /home/staeiou/anaconda3/lib/python3.6/site-packages (from pandas)
    Requirement already satisfied: six>=1.5 in /home/staeiou/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2->pandas)



```python
import mwviews
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import wikipedia
%matplotlib inline
sns.set(font_scale=1.5)
```

## Data

The .txt files are manually curated lists of titles, based on first copying and pasting the columns displaying the names of the members of Congress at 
[List_of_United_States_Senators_in_the_115th_Congress_by_seniority](http://enwp.org/List_of_United_States_Senators_in_the_115th_Congress_by_seniority) and [List_of_United_States_Representatives_in_the_115th_Congress_by_seniority](http://enwp.org/List_of_United_States_Representatives_in_the_115th_Congress_by_seniority). Then each of the article links was manually examined to make sure they match the linked page, and updated if, for example, the text said "Dan Sullivan" but the article was at "Dan Sullivan (U.S. Senator)". Much thanks to [Amy Johnson](http://web.mit.edu/hasts/graduate/johnson.html) who helped curate these lists.

I tried programmatically getting lists of all current members of Congress, my failed attempts can be found at the end.


The files have one title per line, so we read it in and split it into a list with ```.split("\n")```


```python
with open("senators.txt") as f:
    senate_txt = f.read()

senate_list = senate_txt.split("\n")
```


```python
senate_list[0:5]
```




    ['Richard Shelby',
     'Luther Strange',
     'Lisa Murkowski',
     'Dan Sullivan (U.S. Senator)',
     'John McCain']



Checking the length of the list, we see it has 100, which is good! 


```python
len(senate_list)
```




    100



We do the same with the house list, and we get 431 because there are currently some vacancies.


```python
with open("house_reps.txt") as f:
    house_txt = f.read()
    
house_list = house_txt.split("\n")
```


```python
house_list[0:5]
```




    ['Bradley Byrne', 'Martha Roby', 'Mike Rogers', 'Robert Aderholt', 'Mo Brooks']




```python
len(house_list)
```




    431




```python
senate_list_page = wikipedia.page("List_of_United_States_Senators_in_the_115th_Congress_by_seniority")
```


```python
senate_list_auto = []
list_len = len(senate_list_page.links)
count = 0

for page in senate_list_page.links:
    try:
        page_obj = wikipedia.page(page)
        for cat_name in page_obj.categories:
                if cat_name.find("United States Senators from") >=0:
                    senate_list_auto.append(page)
                    break
    except Exception as e:
        pass
    
    count = count + 1
    if count % 25 == 0:
        print(count, count/list_len, "%")
```

    25 0.0377643504531722 %
    50 0.0755287009063444 %
    75 0.11329305135951662 %
    100 0.1510574018126888 %
    125 0.18882175226586104 %
    150 0.22658610271903323 %
    175 0.26435045317220546 %
    200 0.3021148036253776 %
    225 0.33987915407854985 %
    250 0.3776435045317221 %
    275 0.41540785498489424 %
    300 0.45317220543806647 %
    325 0.4909365558912387 %
    350 0.5287009063444109 %
    375 0.5664652567975831 %


    /home/staeiou/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.
    
    The code that caused this warning is on line 193 of the file /home/staeiou/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:
    
     BeautifulSoup([your markup])
    
    to this:
    
     BeautifulSoup([your markup], "lxml")
    
      markup_type=markup_type))


    400 0.6042296072507553 %
    425 0.6419939577039275 %
    450 0.6797583081570997 %
    475 0.7175226586102719 %
    500 0.7552870090634441 %
    525 0.7930513595166163 %
    550 0.8308157099697885 %
    575 0.8685800604229608 %
    600 0.9063444108761329 %
    625 0.9441087613293051 %
    650 0.9818731117824774 %



```python
senate_list_auto
```




    ['Al Franken',
     'Amy Klobuchar',
     'Angus King',
     'Ben Cardin',
     'Ben Sasse',
     'Bernie Sanders',
     'Bill Cassidy',
     'Bill Nelson',
     'Bob Casey Jr.',
     'Bob Corker',
     'Bob Menendez',
     'Brian Schatz',
     'Catherine Cortez Masto',
     'Chris Coons',
     'Chris Murphy (Connecticut politician)',
     'Chuck Grassley',
     'Chuck Schumer',
     'Claire McCaskill',
     'Cory Booker',
     'Cory Gardner',
     'Dan Sullivan (senator)',
     'David Perdue',
     'Dean Heller',
     'Deb Fischer',
     'Debbie Stabenow',
     'Dianne Feinstein',
     'Dick Durbin',
     'Ed Markey',
     'Elizabeth Warren',
     'Gary Peters (politician)',
     'Heidi Heitkamp',
     'Jack Reed (politician)',
     'James Lankford',
     'Jeanne Shaheen',
     'Jeff Flake',
     'Jeff Merkley',
     'Jeff Sessions',
     'Jerry Moran',
     'Jim Inhofe',
     'Jim Risch',
     'Joe Donnelly',
     'Joe Manchin',
     'John Barrasso',
     'John Boozman',
     'John Cornyn',
     'John Hoeven',
     'John McCain',
     'John Neely Kennedy',
     'John Thune',
     'Johnny Isakson',
     'Jon Tester',
     'Joni Ernst',
     'Kamala Harris',
     'Kirsten Gillibrand',
     'Lamar Alexander',
     'Lindsey Graham',
     'Lisa Murkowski',
     'List of United States Senators from Alabama',
     'List of United States Senators from Alaska',
     'List of United States Senators from Arizona',
     'List of United States Senators from Arkansas',
     'List of United States Senators from California',
     'List of United States Senators from Colorado',
     'List of United States Senators from Connecticut',
     'List of United States Senators from Delaware',
     'List of United States Senators from Florida',
     'List of United States Senators from Georgia',
     'List of United States Senators from Hawaii',
     'List of United States Senators from Idaho',
     'List of United States Senators from Illinois',
     'List of United States Senators from Indiana',
     'List of United States Senators from Iowa',
     'List of United States Senators from Kansas',
     'List of United States Senators from Kentucky',
     'List of United States Senators from Louisiana',
     'List of United States Senators from Maine',
     'List of United States Senators from Maryland',
     'List of United States Senators from Massachusetts',
     'List of United States Senators from Michigan',
     'List of United States Senators from Minnesota',
     'List of United States Senators from Mississippi',
     'List of United States Senators from Missouri',
     'List of United States Senators from Montana',
     'List of United States Senators from Nebraska',
     'List of United States Senators from Nevada',
     'List of United States Senators from New Hampshire',
     'List of United States Senators from New Jersey',
     'List of United States Senators from New Mexico',
     'List of United States Senators from New York',
     'List of United States Senators from North Carolina',
     'List of United States Senators from North Dakota',
     'List of United States Senators from Ohio',
     'List of United States Senators from Oklahoma',
     'List of United States Senators from Oregon',
     'List of United States Senators from Pennsylvania',
     'List of United States Senators from Rhode Island',
     'List of United States Senators from South Carolina',
     'List of United States Senators from South Dakota',
     'List of United States Senators from Tennessee',
     'List of United States Senators from Texas',
     'List of United States Senators from Utah',
     'List of United States Senators from Vermont',
     'List of United States Senators from Virginia',
     'List of United States Senators from Washington',
     'List of United States Senators from West Virginia',
     'List of United States Senators from Wisconsin',
     'List of United States Senators from Wyoming',
     'Luther Strange',
     'Maggie Hassan',
     'Marco Rubio',
     'Maria Cantwell',
     'Mark Warner',
     'Martin Heinrich',
     'Mazie Hirono',
     'Michael Bennet',
     'Mike Crapo',
     'Mike Enzi',
     'Mike Lee (U.S. politician)',
     'Mike Rounds',
     'Mitch McConnell',
     'Orrin Hatch',
     'Pat Roberts',
     'Pat Toomey',
     'Patrick Leahy',
     'Patty Murray',
     'Phil Gramm',
     'Rand Paul',
     'Richard Blumenthal',
     'Richard Burr',
     'Richard Shelby',
     'Rob Portman',
     'Roger Wicker',
     'Ron Johnson (Wisconsin politician)',
     'Ron Wyden',
     'Roy Blunt',
     'Sheldon Whitehouse',
     'Shelley Moore Capito',
     'Sherrod Brown',
     'Steve Daines',
     'Susan Collins',
     'Tammy Baldwin',
     'Tammy Duckworth',
     'Ted Cruz',
     'Thad Cochran',
     'Thom Tillis',
     'Tim Kaine',
     'Tim Scott',
     'Todd Young',
     'Tom Carper',
     'Tom Cotton',
     'Tom Udall']




```python
house_list_page = wikipedia.page("Seniority_in_the_United_States_House_of_Representatives")
```


```python
house_list_auto = []
list_len = len(house_list_page.links)
count = 0

for page in house_list_page.links:
    try:
        page_obj = wikipedia.page(page)
        for cat_name in page_obj.categories:
            if cat_name.find("Members of the United States House of Representatives") >=0:
                house_list_auto.append(page)
                break        
    except Exception as e:
        break

    count = count + 1
    if count % 25 == 0:
        print(count, count/list_len, "%")           
```

    25 0.01749475157452764 %
    50 0.03498950314905528 %
    75 0.052484254723582924 %
    100 0.06997900629811056 %
    125 0.08747375787263821 %
    150 0.10496850944716585 %
    175 0.1224632610216935 %
    200 0.13995801259622112 %
    225 0.15745276417074877 %
    250 0.17494751574527642 %
    275 0.19244226731980407 %
    300 0.2099370188943317 %
    325 0.22743177046885935 %
    350 0.244926522043387 %
    375 0.2624212736179146 %
    400 0.27991602519244224 %
    425 0.2974107767669699 %
    450 0.31490552834149754 %
    475 0.33240027991602517 %
    500 0.34989503149055284 %
    525 0.36738978306508047 %
    550 0.38488453463960814 %
    575 0.40237928621413577 %
    600 0.4198740377886634 %
    625 0.43736878936319107 %
    650 0.4548635409377187 %
    675 0.4723582925122463 %
    700 0.489853044086774 %
    725 0.5073477956613016 %
    750 0.5248425472358292 %
    775 0.5423372988103569 %
    800 0.5598320503848845 %
    825 0.5773268019594122 %
    850 0.5948215535339398 %
    875 0.6123163051084675 %



```python

```

## Querying the pageviews API

mwviews makes it much easier to query the pageviews API, so we don't have to directly call the API. We can also pass in a (very long!) list of pages to get data. We get back a nice JSON formatted response, which pandas can convert to a dataframe without any help.

The main way to interact via mwviews is the PageviewsClient object, which we will create as `p` for short.


```python

```


```python

```


```python
from mwviews.api import PageviewsClient

p = PageviewsClient()
```

When we query the API for the view data, we can set many variables in ```p.article_views()```. We pass in ```senate_list``` as our list of articles. Granularity can be monthly or daily, and start and end dates are formatted as YYYYMMDDHH. You have to include precise start and end dates by the hour, and it will not give super helpful error messages if you do things lie set your end date before your start date or things like that. And also know that the pageview data only goes back a few years.


```python
senate_views = p.article_views(project='en.wikipedia', 
                            articles=senate_list, 
                            granularity='monthly', 
                            start='2016040100', 
                            end='2017033123')

senate_df = pd.DataFrame(senate_views)
```

If we peek at the first 10 rows and 5 columns in the dataframe, we see it is formatted with one row per page, and one column per month:


```python
senate_df.ix[0:10, 0:5]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2016-04-01 00:00:00</th>
      <th>2016-05-01 00:00:00</th>
      <th>2016-06-01 00:00:00</th>
      <th>2016-07-01 00:00:00</th>
      <th>2016-08-01 00:00:00</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Al_Franken</th>
      <td>43087.0</td>
      <td>66366.0</td>
      <td>53539.0</td>
      <td>143641.0</td>
      <td>37679.0</td>
    </tr>
    <tr>
      <th>Amy_Klobuchar</th>
      <td>19740.0</td>
      <td>16663.0</td>
      <td>19394.0</td>
      <td>36931.0</td>
      <td>10618.0</td>
    </tr>
    <tr>
      <th>Angus_King</th>
      <td>13951.0</td>
      <td>13341.0</td>
      <td>16458.0</td>
      <td>16043.0</td>
      <td>15773.0</td>
    </tr>
    <tr>
      <th>Ben_Cardin</th>
      <td>7733.0</td>
      <td>5532.0</td>
      <td>7198.0</td>
      <td>6656.0</td>
      <td>6384.0</td>
    </tr>
    <tr>
      <th>Ben_Sasse</th>
      <td>9943.0</td>
      <td>78686.0</td>
      <td>22201.0</td>
      <td>21502.0</td>
      <td>11996.0</td>
    </tr>
    <tr>
      <th>Bernie_Sanders</th>
      <td>1337991.0</td>
      <td>787078.0</td>
      <td>582409.0</td>
      <td>684501.0</td>
      <td>203070.0</td>
    </tr>
    <tr>
      <th>Bill_Cassidy</th>
      <td>5047.0</td>
      <td>4644.0</td>
      <td>4628.0</td>
      <td>6895.0</td>
      <td>5019.0</td>
    </tr>
    <tr>
      <th>Bill_Nelson</th>
      <td>12413.0</td>
      <td>11750.0</td>
      <td>30518.0</td>
      <td>13005.0</td>
      <td>9760.0</td>
    </tr>
    <tr>
      <th>Bob_Casey_Jr.</th>
      <td>95.0</td>
      <td>2146.0</td>
      <td>5226.0</td>
      <td>8934.0</td>
      <td>3764.0</td>
    </tr>
    <tr>
      <th>Bob_Corker</th>
      <td>8403.0</td>
      <td>53781.0</td>
      <td>21864.0</td>
      <td>41705.0</td>
      <td>7142.0</td>
    </tr>
  </tbody>
</table>
</div>



We transpose this (switching rows and columns), then set the index of each row to a more readable string, Year-Month:


```python
senate_df = senate_df.transpose()
senate_df = senate_df.set_index(senate_df.index.strftime("%Y-%m")).sort_index()
```


```python
senate_df.ix[0:5, 0:10]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Al_Franken</th>
      <th>Amy_Klobuchar</th>
      <th>Angus_King</th>
      <th>Ben_Cardin</th>
      <th>Ben_Sasse</th>
      <th>Bernie_Sanders</th>
      <th>Bill_Cassidy</th>
      <th>Bill_Nelson</th>
      <th>Bob_Casey_Jr.</th>
      <th>Bob_Corker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-04</th>
      <td>43087.0</td>
      <td>19740.0</td>
      <td>13951.0</td>
      <td>7733.0</td>
      <td>9943.0</td>
      <td>1337991.0</td>
      <td>5047.0</td>
      <td>12413.0</td>
      <td>95.0</td>
      <td>8403.0</td>
    </tr>
    <tr>
      <th>2016-05</th>
      <td>66366.0</td>
      <td>16663.0</td>
      <td>13341.0</td>
      <td>5532.0</td>
      <td>78686.0</td>
      <td>787078.0</td>
      <td>4644.0</td>
      <td>11750.0</td>
      <td>2146.0</td>
      <td>53781.0</td>
    </tr>
    <tr>
      <th>2016-06</th>
      <td>53539.0</td>
      <td>19394.0</td>
      <td>16458.0</td>
      <td>7198.0</td>
      <td>22201.0</td>
      <td>582409.0</td>
      <td>4628.0</td>
      <td>30518.0</td>
      <td>5226.0</td>
      <td>21864.0</td>
    </tr>
    <tr>
      <th>2016-07</th>
      <td>143641.0</td>
      <td>36931.0</td>
      <td>16043.0</td>
      <td>6656.0</td>
      <td>21502.0</td>
      <td>684501.0</td>
      <td>6895.0</td>
      <td>13005.0</td>
      <td>8934.0</td>
      <td>41705.0</td>
    </tr>
    <tr>
      <th>2016-08</th>
      <td>37679.0</td>
      <td>10618.0</td>
      <td>15773.0</td>
      <td>6384.0</td>
      <td>11996.0</td>
      <td>203070.0</td>
      <td>5019.0</td>
      <td>9760.0</td>
      <td>3764.0</td>
      <td>7142.0</td>
    </tr>
  </tbody>
</table>
</div>



We can get the sum for each page by running .sum(), and we can peek into the first five pages:


```python
senate_sum = senate_df.sum()
senate_sum[0:5]
```




    Al_Franken       1400454.0
    Amy_Klobuchar     340114.0
    Angus_King        281545.0
    Ben_Cardin        135774.0
    Ben_Sasse         384434.0
    dtype: float64



We can get the sum for each month by transposing back and running .sum() on the dataframe:


```python
senate_monthly_sum = senate_df.transpose().sum()
senate_monthly_sum
```




    2016-04    3931109.0
    2016-05    3493508.0
    2016-06    3358614.0
    2016-07    6661905.0
    2016-08    2012990.0
    2016-09    2000842.0
    2016-10    3647561.0
    2016-11    6361233.0
    2016-12    2352725.0
    2017-01    5803284.0
    2017-02    4912876.0
    2017-03    3882319.0
    dtype: float64



And we can get the sum of all the months from 2016-04 to 2016-03 by summing the monthly sum, which gives us 48.4 million pageviews:


```python
senate_monthly_sum.sum()
```




    48418966.0



We can use the built-in plotting functionality in pandas dataframes to show a monthly plot. You can adjust kind to be many types, including bar, line, and area.


```python
fig = plt.figure()
fig.suptitle("Monthly Wikipedia pageviews for current U.S. Senators")
plt.ticklabel_format(style = 'plain')

ax = senate_monthly_sum.plot(kind='barh', figsize=[12,6])
ax.set_xlabel("Monthly pageviews")
ax.set_ylabel("Month")

```




    <matplotlib.text.Text at 0x7f6328bea3c8>




![png](output_38_1.png)


### The House

We do the same thing for the House of Representatives, only with different variables. Recall that ```house_list``` is our list of titles:


```python
house_list[0:5]
```




    ['Bradley Byrne', 'Martha Roby', 'Mike Rogers', 'Robert Aderholt', 'Mo Brooks']




```python
house_views = p.article_views(project='en.wikipedia', 
                              articles=house_list, 
                              granularity='monthly', 
                              start='2016040100', 
                              end='2017033123')
                              
house_df = pd.DataFrame(house_views)
house_df.ix[0:5, 0:5]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2016-04-01 00:00:00</th>
      <th>2016-05-01 00:00:00</th>
      <th>2016-06-01 00:00:00</th>
      <th>2016-07-01 00:00:00</th>
      <th>2016-08-01 00:00:00</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adam_Kinzinger</th>
      <td>6579.0</td>
      <td>10515.0</td>
      <td>12002.0</td>
      <td>7217.0</td>
      <td>22613.0</td>
    </tr>
    <tr>
      <th>Adam_Schiff</th>
      <td>6541.0</td>
      <td>6649.0</td>
      <td>12993.0</td>
      <td>7501.0</td>
      <td>4760.0</td>
    </tr>
    <tr>
      <th>Adam_Smith_(politician)</th>
      <td>2712.0</td>
      <td>2400.0</td>
      <td>2770.0</td>
      <td>2939.0</td>
      <td>2458.0</td>
    </tr>
    <tr>
      <th>Adrian_Smith_(politician)</th>
      <td>1368.0</td>
      <td>1295.0</td>
      <td>1285.0</td>
      <td>1151.0</td>
      <td>1432.0</td>
    </tr>
    <tr>
      <th>Adriano_Espaillat</th>
      <td>1296.0</td>
      <td>1061.0</td>
      <td>5591.0</td>
      <td>5360.0</td>
      <td>1729.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
house_df = house_df.transpose()
house_df = house_df.set_index(house_df.index.strftime("%Y-%m")).sort_index()
house_df.ix[0:5, 0:5]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Adam_Kinzinger</th>
      <th>Adam_Schiff</th>
      <th>Adam_Smith_(politician)</th>
      <th>Adrian_Smith_(politician)</th>
      <th>Adriano_Espaillat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-04</th>
      <td>6579.0</td>
      <td>6541.0</td>
      <td>2712.0</td>
      <td>1368.0</td>
      <td>1296.0</td>
    </tr>
    <tr>
      <th>2016-05</th>
      <td>10515.0</td>
      <td>6649.0</td>
      <td>2400.0</td>
      <td>1295.0</td>
      <td>1061.0</td>
    </tr>
    <tr>
      <th>2016-06</th>
      <td>12002.0</td>
      <td>12993.0</td>
      <td>2770.0</td>
      <td>1285.0</td>
      <td>5591.0</td>
    </tr>
    <tr>
      <th>2016-07</th>
      <td>7217.0</td>
      <td>7501.0</td>
      <td>2939.0</td>
      <td>1151.0</td>
      <td>5360.0</td>
    </tr>
    <tr>
      <th>2016-08</th>
      <td>22613.0</td>
      <td>4760.0</td>
      <td>2458.0</td>
      <td>1432.0</td>
      <td>1729.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
house_sum = house_df.sum()
house_sum[0:5]
```




    Adam_Kinzinger               162674.0
    Adam_Schiff                  406908.0
    Adam_Smith_(politician)       40274.0
    Adrian_Smith_(politician)     19851.0
    Adriano_Espaillat             67980.0
    dtype: float64




```python
house_monthly_sum = house_df.transpose().sum()
house_monthly_sum
```




    2016-04    1727960.0
    2016-05    1940369.0
    2016-06    1983199.0
    2016-07    3009143.0
    2016-08    1644636.0
    2016-09    1609682.0
    2016-10    2558133.0
    2016-11    5095820.0
    2016-12    2408666.0
    2017-01    4190713.0
    2017-02    3905450.0
    2017-03    5931667.0
    dtype: float64




```python
house_monthly_sum.sum()
```




    36005438.0



This gives us 36 million total pageviews for House reps.


```python
fig = plt.figure()
fig.suptitle("Monthly Wikipedia pageviews for current U.S. House of Representatives")
plt.ticklabel_format(style = 'plain')

ax = house_monthly_sum.plot(kind='barh', figsize=[12,6])
ax.set_xlabel("Monthly pageviews")
ax.set_ylabel("Month")

```




    <matplotlib.text.Text at 0x7f630fd50be0>




![png](output_47_1.png)


## Combining the datasets

We have to transpose each dataset back, then append one to the other:


```python
congress_df = house_df.transpose().append(senate_df.transpose())
congress_df.ix[0:10,0:10]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2016-04</th>
      <th>2016-05</th>
      <th>2016-06</th>
      <th>2016-07</th>
      <th>2016-08</th>
      <th>2016-09</th>
      <th>2016-10</th>
      <th>2016-11</th>
      <th>2016-12</th>
      <th>2017-01</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adam_Kinzinger</th>
      <td>6579.0</td>
      <td>10515.0</td>
      <td>12002.0</td>
      <td>7217.0</td>
      <td>22613.0</td>
      <td>6846.0</td>
      <td>6869.0</td>
      <td>19077.0</td>
      <td>14200.0</td>
      <td>18531.0</td>
    </tr>
    <tr>
      <th>Adam_Schiff</th>
      <td>6541.0</td>
      <td>6649.0</td>
      <td>12993.0</td>
      <td>7501.0</td>
      <td>4760.0</td>
      <td>5068.0</td>
      <td>8318.0</td>
      <td>13906.0</td>
      <td>17191.0</td>
      <td>20320.0</td>
    </tr>
    <tr>
      <th>Adam_Smith_(politician)</th>
      <td>2712.0</td>
      <td>2400.0</td>
      <td>2770.0</td>
      <td>2939.0</td>
      <td>2458.0</td>
      <td>2802.0</td>
      <td>2841.0</td>
      <td>4745.0</td>
      <td>3301.0</td>
      <td>5510.0</td>
    </tr>
    <tr>
      <th>Adrian_Smith_(politician)</th>
      <td>1368.0</td>
      <td>1295.0</td>
      <td>1285.0</td>
      <td>1151.0</td>
      <td>1432.0</td>
      <td>1363.0</td>
      <td>2004.0</td>
      <td>2292.0</td>
      <td>1481.0</td>
      <td>1967.0</td>
    </tr>
    <tr>
      <th>Adriano_Espaillat</th>
      <td>1296.0</td>
      <td>1061.0</td>
      <td>5591.0</td>
      <td>5360.0</td>
      <td>1729.0</td>
      <td>2754.0</td>
      <td>2017.0</td>
      <td>11937.0</td>
      <td>4421.0</td>
      <td>15559.0</td>
    </tr>
    <tr>
      <th>Al_Green_(politician)</th>
      <td>4527.0</td>
      <td>3047.0</td>
      <td>3243.0</td>
      <td>3141.0</td>
      <td>2028.0</td>
      <td>2878.0</td>
      <td>2915.0</td>
      <td>3549.0</td>
      <td>2382.0</td>
      <td>6651.0</td>
    </tr>
    <tr>
      <th>Al_Lawson</th>
      <td>30.0</td>
      <td>36.0</td>
      <td>34.0</td>
      <td>68.0</td>
      <td>479.0</td>
      <td>1070.0</td>
      <td>1185.0</td>
      <td>3856.0</td>
      <td>2326.0</td>
      <td>4971.0</td>
    </tr>
    <tr>
      <th>Alan_Lowenthal</th>
      <td>2164.0</td>
      <td>2151.0</td>
      <td>2575.0</td>
      <td>1760.0</td>
      <td>1597.0</td>
      <td>1455.0</td>
      <td>2278.0</td>
      <td>3401.0</td>
      <td>1985.0</td>
      <td>3135.0</td>
    </tr>
    <tr>
      <th>Albio_Sires</th>
      <td>2348.0</td>
      <td>2126.0</td>
      <td>2467.0</td>
      <td>1960.0</td>
      <td>1679.0</td>
      <td>3582.0</td>
      <td>2483.0</td>
      <td>4875.0</td>
      <td>1993.0</td>
      <td>3175.0</td>
    </tr>
    <tr>
      <th>Alcee_Hastings</th>
      <td>4795.0</td>
      <td>5958.0</td>
      <td>5533.0</td>
      <td>9017.0</td>
      <td>4581.0</td>
      <td>4075.0</td>
      <td>4711.0</td>
      <td>6982.0</td>
      <td>3866.0</td>
      <td>8475.0</td>
    </tr>
  </tbody>
</table>
</div>




```python

```


```python
congress_monthly_sum = congress_df.sum()
congress_monthly_sum
```




    2016-04     5659069.0
    2016-05     5433877.0
    2016-06     5341813.0
    2016-07     9671048.0
    2016-08     3657626.0
    2016-09     3610524.0
    2016-10     6205694.0
    2016-11    11457053.0
    2016-12     4761391.0
    2017-01     9993997.0
    2017-02     8818326.0
    2017-03     9813986.0
    dtype: float64



Then to find the total pageviews, run sum on the sum. This is 84.4 million pageviews from March 2016 to March 2017 for all U.S. Members of Congress:


```python
congress_monthly_sum.sum()
```




    84424404.0




```python
fig = plt.figure()
fig.suptitle("Monthly Wikipedia pageviews for current U.S. Members of Congress")
plt.ticklabel_format(style = 'plain')

ax = congress_monthly_sum.plot(kind='barh', figsize=[12,6])

ax.set_xlabel("Monthly pageviews")
ax.set_ylabel("Month")


```




    <matplotlib.text.Text at 0x7f6328b04358>




![png](output_54_1.png)


## Plotting a single page's views over time

We can query the dataframe by index for a specific page, then plot it:


```python
fig = plt.figure()
fig.suptitle("Monthly Wikipedia pageviews for Al Lawson")
plt.ticklabel_format(style = 'plain')

ax = congress_df.ix['Al_Lawson'].plot(kind='barh')

ax.set_xlabel("Monthly pageviews")
ax.set_ylabel("Month")
```




    <matplotlib.text.Text at 0x7f6302cdec50>




![png](output_57_1.png)


## Output data

We will export these to a folder called data, in csv and excel formats:


```python
house_df.to_csv("data/house_views.csv")
house_df.to_excel("data/house_views.xlsx")

senate_df.to_csv("data/senate_views.csv")
senate_df.to_excel("data/senate_views.xlsx")
```


```python

```

## Old code for trying to programatically get lists of members of Congress


```python
# used to stop "Restart and run all" execution 

assert False is True
```


    ---------------------------------------------------------------------------

    AssertionError                            Traceback (most recent call last)

    <ipython-input-31-20e02078d1a5> in <module>()
          1 # used to stop "Restart and run all" execution
          2 
    ----> 3 assert False is True
    

    AssertionError: 



```python
site = pywikibot.Site(code="en")
site.login()
```


```python

```


```python
rep_page = pywikibot.Page(site, title="List_of_United_States_Representatives_in_the_115th_Congress_by_seniority")
```


```python
rep_list = []
for page in rep_page.linkedPages():
    has_from_cat = False
    has_births_cat = False
    #print(page.title())
    for category in page.categories():
        #print("\t", category.title())
        if category.title().find("Category:Members of the United States House of Representatives from") >= 0:
            has_from_cat = True
        if category.title().find("births") >= 0:
            has_births_cat = True
        if has_births_cat & has_from_cat:
            rep_list.append(page.title())
            break
```


```python
senate_list = []
for page in rep_page.linkedPages():
    has_from_cat = False
    has_births_cat = False
    #print(page.title())
    for category in page.categories():
        #print("\t", category.title())
        if category.title().find("United States Senators") >= 0:
            has_from_cat = True
        if category.title().find("births") >= 0:
            has_births_cat = True
        if has_from_cat:
            senate_list.append(page.title())
            break
            
```
